{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what data we'd like to get from the API, let's try to create a training set. To get started we'll try to get ~10,000 games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found API Key.\n"
     ]
    }
   ],
   "source": [
    "if 'STEAM_API_KEY' not in os.environ:\n",
    "  print(\"No API Key :(\")\n",
    "else:\n",
    "  print(\"Found API Key.\")\n",
    "  STEAM_API_KEY = os.environ['STEAM_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I've modified the `__request` method to handle `429` (Too Many Request) errors. It looks like we can't really hit the API more than once every 5 seconds and that if we're limited, we have to wait for ~15 seconds.\n",
    "\n",
    "None of this is based off of any kind of documentation and could probably change at a moment's notice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://api.steampowered.com'\n",
    "\n",
    "def __request(method, path, **kwargs):\n",
    "  url = base_url + path\n",
    "  kwargs.setdefault('params', dict()).update(key=STEAM_API_KEY)\n",
    "  response = requests.request(method, url, **kwargs)\n",
    "\n",
    "  if response.status_code == 429:\n",
    "    print(\"Backing off.\")\n",
    "    print(response.headers)\n",
    "    time.sleep(15)\n",
    "    response = requests.request(method, url, **kwargs)\n",
    "  try:\n",
    "    response_json = response.json()\n",
    "    return response_json\n",
    "  except:\n",
    "    print(\"Error converting to json.\")\n",
    "    print(response)\n",
    "  \n",
    "\n",
    "def get_match_history_by_seq_num(seq_num, num_matches, **params):\n",
    "  path = '/IDOTA2Match_570/GetMatchHistoryBySequenceNum/V001'\n",
    "  params.update(start_at_match_seq_num=seq_num)\n",
    "  params.update(matches_requested=num_matches)  \n",
    "  return __request('get', path, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The starting sequence number.\n",
    "current_seq_num = 5126114401\n",
    "# The maximum number of matches the API will return at once.\n",
    "num_matches_per_request = 100\n",
    "# Total number of matches we'd like to save.\n",
    "num_total_matches = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off.\n",
      "{'Content-Type': 'text/html; charset=UTF-8', 'Content-Length': '108', 'Expires': 'Sat, 07 Aug 2021 23:03:46 GMT', 'Cache-Control': 'max-age=0, no-cache, no-store', 'Pragma': 'no-cache', 'Date': 'Sat, 07 Aug 2021 23:03:46 GMT', 'Connection': 'keep-alive'}\n",
      "Backing off.\n",
      "{'Content-Type': 'text/html; charset=UTF-8', 'Content-Length': '108', 'Expires': 'Sat, 07 Aug 2021 23:05:49 GMT', 'Cache-Control': 'max-age=0, no-cache, no-store', 'Pragma': 'no-cache', 'Date': 'Sat, 07 Aug 2021 23:05:49 GMT', 'Connection': 'keep-alive'}\n",
      "Backing off.\n",
      "{'Content-Type': 'text/html; charset=UTF-8', 'Content-Length': '108', 'Expires': 'Sat, 07 Aug 2021 23:10:50 GMT', 'Cache-Control': 'max-age=0, no-cache, no-store', 'Pragma': 'no-cache', 'Date': 'Sat, 07 Aug 2021 23:10:50 GMT', 'Connection': 'keep-alive'}\n"
     ]
    }
   ],
   "source": [
    "training_set = []\n",
    "\n",
    "while len(training_set) < num_total_matches:\n",
    "    # Don't hit the API too frequently.\n",
    "    time.sleep(5)\n",
    "    response = get_match_history_by_seq_num(current_seq_num, num_matches_per_request)\n",
    "    \n",
    "    matches = response['result']['matches']\n",
    "    \n",
    "    if len(matches) != 100:\n",
    "        print(\"Problem. Expected 100 matches. Actual: \", len(matches))\n",
    "        print(response)\n",
    "        break\n",
    "    \n",
    "    for match in matches:\n",
    "        if match['human_players'] != 10:\n",
    "            # We only want \"real\" games of Dota so we're ignoring\n",
    "            # games without 10 human players.\n",
    "            continue\n",
    "        try:\n",
    "            players = match['players']\n",
    "            hero0 = players[0]['hero_id']\n",
    "            hero1 = players[1]['hero_id']\n",
    "            hero2 = players[2]['hero_id']\n",
    "            hero3 = players[3]['hero_id']\n",
    "            hero4 = players[4]['hero_id']\n",
    "            hero5 = players[5]['hero_id']\n",
    "            hero6 = players[6]['hero_id']\n",
    "            hero7 = players[7]['hero_id']\n",
    "            hero8 = players[8]['hero_id']\n",
    "            hero9 = players[9]['hero_id']\n",
    "            radiant_win = match['radiant_win']\n",
    "            training_set.append((hero0, hero1, hero2, hero3, hero4,\n",
    "                                hero5, hero6, hero7, hero8, hero9,\n",
    "                                radiant_win))\n",
    "        except:\n",
    "            print(\"Error:\", match)\n",
    "            break\n",
    "\n",
    "        \n",
    "    current_seq_num -= num_matches_per_request\n",
    "        \n",
    "print(\"Complete. Training set size:\", len(training_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to save our training set so we can feed it to a machine learning classifier later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(training_set, \n",
    "             columns=['hero0', 'hero1', 'hero2', 'hero3', 'hero4',\n",
    "                      'hero5', 'hero6', 'hero7', 'hero8', 'hero9',\n",
    "                      'radiant_win'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"training_set_small.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we can try to traing a classifier on this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
